---
author: khongai
ogImage: /public/assets/2025/10/26/0_intro_ml2.png
pubDatetime: 2025-10-26T15:22:00Z
modDatetime: 2025-10-26T16:52:45.934Z
title: AI 101 - Pháº§n 2, ÄÃ o sÃ¢u ML báº±ng cÃ¡ch tÃ¬m hiá»ƒu má»™t sá»‘ thuáº­t toÃ¡n ML cÆ¡ báº£n vÃ  láº­p trÃ¬nh má»™t sá»‘ vÃ­ dá»¥ cá»¥ thá»ƒ
slug: ai-101-phan2-thu-tim-hieu-ve-ml-va-viet-mot-so-chuong-trinh-ml-co-ban
featured: false
draft: false
tags:
  - AI
description:
  BÃ i viáº¿t nÃ y chÃºng ta sáº½ cÃ¹ng nhau lÃ m tÃ¬m hiá»ƒu má»™t sá»‘ thuáº­t toÃ¡n ML cÆ¡ báº£n.
---

>KhÃ´ng pháº£i lÃ  AI/ML Engineer nhÆ°ng vá»‘n lÃ  ngÆ°á»i â€œÄ‘Ã£ tá»«ng há»c láº­p trÃ¬nhâ€ tÃ´i hiá»ƒu khÃ´ng cÃ³ gÃ¬ giÃºp hiá»ƒu nhanh báº±ng viá»‡c nháº£y vÃ o code má»™t vÃ­ dá»¥ cá»¥ thá»ƒ. Do váº­y tÃ´i nghÄ© vá»›i  má»—i nhÃ³m thuáº­t toÃ¡n AI/ML/DL tÃ´i sáº½ lÃ m vÃ­ dá»¥ vá»›i má»™t thuáº­t toÃ¡n Ä‘Æ¡n giáº£n nháº¥t Ä‘á»ƒ hiá»ƒu code thá»±c táº¿ nÃ³ cháº¡y tháº¿ nÃ o..


## Table of contents

# Má»™t sá»‘ thuáº­t toÃ¡n ML cÆ¡ báº£n 

Sá»‘ lÆ°á»£ng thuáº­t toÃ¡n Machine Learning ráº¥t Ä‘a dáº¡ng, á»Ÿ Ä‘Ã¢y chá»‰ xin minh há»a báº±ng má»™t sÆ¡ Ä‘á»“ Ä‘Æ¡n giáº£n thá»ƒ hiá»‡n â€œÄ‘áº¡i gia Ä‘Ã¬nhâ€ cá»§a cÃ¡c thuáº­t toÃ¡n nÃ y.


![ml algo](/assets/2025/10/26/0_intro_ml2.png)


# Supervised Learning vá»›i Há»“i quy tuyáº¿n tÃ­nh (Linear Regression) - Thuáº­t toÃ¡n Ä‘Æ¡n giáº£n nháº¥t

>(Há»“i quy tuyáº¿n tÃ­nh - NghÄ©a tiáº¿ng viá»‡t â€œhá»“i quyâ€ cÃ³ nghÄ©a lÃ  cÃ¹ng má»™t xu hÆ°á»›ng, tuyáº¿n tÃ­nh nghÄ©a lÃ  má»‘i quan há»‡ tá»‰ lá»‡ thuáº­n). 

## Giá»›i thiá»‡u bÃ i toÃ¡n

**BÃ i toÃ¡n quen thuá»™c:** Dá»± Ä‘oÃ¡n giÃ¡ nhÃ  (y) dá»±a trÃªn diá»‡n tÃ­ch nhÃ  (x). Dá»… tháº¥y ráº±ng trong thá»±c táº¿ cÃ¹ng má»™t Ä‘á»‹a Ä‘iá»ƒm thÃ¬ diá»‡n tÃ­ch tÄƒng â†’ giÃ¡ nhÃ  tÄƒng & giÃ¡ nhÃ  lÃ  giÃ¡ trá»‹ liÃªn tá»¥c nÃªn Ä‘Ã¢y cÃ³ thá»ƒ xem lÃ  lÃ  bÃ i toÃ¡n **Linear Regression**

* Äáº§u vÃ o (Input): Táº­p (x,y) vá»›i x lÃ  m2, vÃ  y lÃ  giÃ¡. 
* Äáº§u ra (Output): Vá»›i x  â†’ dá»± Ä‘oÃ¡n y

## MÃ´ hÃ¬nh toÃ¡n há»c (cÃ´ng thá»©c biá»ƒu diá»…n má»‘i quan há»‡)

MÃ´ hÃ¬nh toÃ¡n há»c chung cho bÃ i toÃ¡n há»“i quy tuyáº¿n thÃ­nh

```mathematica
$$
\hat{y} = w \cdot x + b
$$
```

```mathematica
x : Äáº§u vÃ o (input, vÃ­ dá»¥: diá»‡n tÃ­ch nhÃ )
\hat{y}: Äáº§u ra (dá»± Ä‘oÃ¡n, vÃ­ dá»¥: giÃ¡ nhÃ )
w: Há»‡ sá»‘ (Ä‘á»™ dá»‘c Ä‘Æ°á»ng tháº³ng)
b: Háº±ng sá»‘ chá»‡ch (Ä‘iá»ƒm cáº¯t trá»¥c tung)
```

Váº½ lÃªn nÃ³ lÃ  Ä‘Æ°á»ng tháº³ng

![image.png](attachment:382ca3e1-07b3-4e9c-8e5b-12fa124b0c55:image.png)

## HÃ m má»¥c tiÃªu (Loss function)

á» hÃ¬nh váº½ trÃªn ta tháº¥y cÃ¡c doáº¡n mÃ u xanh (ná»‘i tá»« cháº¥m trÃ²n tá»›i Ä‘Æ°á»ng nÃ©t Ä‘á»©t) chÃ­nh lÃ  sai sá»‘ giá»¯a giÃ¡ trá»‹ thá»±c táº¿ vÃ  Æ°á»›c lÆ°á»£ng.

DÃ¹ng **Mean Squared Error (MSE)** Ä‘á»ƒ Ä‘o sai sá»‘ giá»¯a dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿:

```mathematica
[
J(w,b) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2
]
```

**â†’ Má»¥c tiÃªu:** tÃ¬m w, b sao cho J nhá» nháº¥t <=> **Ta nháº­n tháº¥y ráº±ng cÃ¡c bÃ i toÃ¡n ML vá» cÆ¡ báº£n lÃ  Ä‘i tÃ¬m giÃ¡ trá»‹ Ä‘á»ƒ hÃ m má»¥c tiÃªu nhá» nháº¥t**

## CÃ¡ch há»c - QuÃ¡ trÃ¬nh há»c

Trong toÃ¡n há»c cÃ¡c bÃ i toÃ¡n nÃ y thá»±c ra cÃ³ nhiá»u cÃ¡ch giáº£i. "Äá»c qua" (vÃ¬ tÃ´i khÃ´ng cÃ³ nhu cáº§u Ä‘i sÃ¢u vá» toÃ¡n) tÃ´i tháº¥y ngÆ°á»i ta cÃ³ 2 phÆ°Æ¡ng phÃ¡p chÃ­nh lÃ :

Sau khi tÃ¬m Ä‘Æ°á»£c cÃ¡ch giáº£i bÃ i toÃ¡n nÃ y ta Ä‘i vÃ o implement chÃºng diá»…n dáº£i dÆ°á»›i dáº¡ng code mÃ  thÃ´i (Tháº­t ra lÃ  cÃ³ lib há» viáº¿t sáºµn háº¿t rá»“i).

### Code láº­p trÃ¬nh

TrÆ°á»›c khi cÃ i Ä‘áº·t chÆ°Æ¡ng trÃ¬nh báº±ng python ta cáº§n giá»›i thiá»‡u khÃ¡i niá»‡m táº­p train vÃ  táº­p test. Dá»¯ liá»‡u ban Ä‘áº§u thÆ°á»ng Ä‘Æ°á»£c tÃ¡ch thÃ nh 2 táº­p train vÃ  test. 

* Táº­p train (Training set): LÃ  pháº§n dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.

Má»¥c tiÃªu: Ä‘á»ƒ mÃ´ hÃ¬nh â€œhá»câ€ Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a cÃ¡c Ä‘áº·c trÆ°ng (features) vÃ  nhÃ£n (labels).

* Táº­p test (Testing set): LÃ  pháº§n dá»¯ liá»‡u tÃ¡ch riÃªng ra, khÃ´ng dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n, mÃ  chá»‰ dÃ¹ng Ä‘á»ƒ kiá»ƒm tra xem mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ³ tá»‘t khÃ´ng.

Má»¥c tiÃªu: Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c (accuracy), sai sá»‘ (error), kháº£ nÄƒng dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u má»›i chÆ°a tá»«ng tháº¥y.

*Náº¿u báº¡n dÃ¹ng cÃ¹ng má»™t dá»¯ liá»‡u Ä‘á»ƒ vá»«a train vá»«a test, mÃ´ hÃ¬nh sáº½ dá»… bá»‹ â€œhá»c váº¹tâ€ (overfitting), tá»©c lÃ  chá»‰ nhá»› dá»¯ liá»‡u cÅ© mÃ  khÃ´ng tá»•ng quÃ¡t Ä‘Æ°á»£c vá»›i dá»¯ liá»‡u má»›i*



```python
# =====================================================
# 1ï¸âƒ£ Import thÆ° viá»‡n
# =====================================================
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# =====================================================
# 2ï¸âƒ£ Táº¡o dá»¯ liá»‡u máº«u
# =====================================================
# x: diá»‡n tÃ­ch nhÃ  (m2)
# y: giÃ¡ nhÃ  (tá»· VNÄ)
x = np.array([50, 60, 70, 80, 90, 100, 120, 150]).reshape(-1, 1)
y = np.array([1.6, 1.9, 2.2, 2.6, 3.0, 3.4, 4.0, 5.0])

# =====================================================
# 3ï¸âƒ£ Chia dá»¯ liá»‡u train/test
# =====================================================
X_train, X_test, y_train, y_test = train_test_split(
    x, y, test_size=0.25, random_state=42
)

# =====================================================
# 4ï¸âƒ£ Huáº¥n luyá»‡n mÃ´ hÃ¬nh Linear Regression
# =====================================================
model = LinearRegression()
model.fit(X_train, y_train)

# Há»‡ sá»‘ w vÃ  b mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c
w = model.coef_[0]
b = model.intercept_

print(f"Há»‡ sá»‘ w (Ä‘á»™ dá»‘c): {w:.4f}")
print(f"Há»‡ sá»‘ b (chá»‡ch): {b:.4f}")

# =====================================================
# 5ï¸âƒ£ Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
# =====================================================
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nSai sá»‘ trung bÃ¬nh bÃ¬nh phÆ°Æ¡ng (MSE): {mse:.4f}")
print(f"Há»‡ sá»‘ xÃ¡c Ä‘á»‹nh RÂ²: {r2:.4f}")

# =====================================================
# 6ï¸âƒ£ Váº½ biá»ƒu Ä‘á»“
# =====================================================
plt.scatter(x, y, color='blue', label='Dá»¯ liá»‡u thá»±c táº¿')       # CÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u tháº­t
plt.plot(x, model.predict(x), color='red', label='ÄÆ°á»ng há»“i quy')  # ÄÆ°á»ng tháº³ng dá»± Ä‘oÃ¡n
plt.xlabel('Diá»‡n tÃ­ch (mÂ²)')
plt.ylabel('GiÃ¡ nhÃ  (tá»· VNÄ)')
plt.title('BÃ i toÃ¡n Há»“i quy tuyáº¿n tÃ­nh - Dá»± Ä‘oÃ¡n giÃ¡ nhÃ ')
plt.legend()
plt.show()

# =====================================================
# 7ï¸âƒ£ Dá»± Ä‘oÃ¡n giÃ¡ nhÃ  má»›i
# =====================================================
new_house = np.array([[110]]) #Diá»‡n tÃ­ch 110m2
predicted_price = model.predict(new_house)
print(f"\nğŸ  Dá»± Ä‘oÃ¡n giÃ¡ cho nhÃ  110 mÂ²: {predicted_price[0]:.2f} tá»· VNÄ")

```

LÃºc nÃ y nháº­p vÃ o diá»‡n tÃ­ch sáº½ ra giÃ¡ nhÃ  tÆ°Æ¡ng á»©ng. QuÃ¡ Ä‘Æ¡n giáº£n pháº£i khÃ´ng :) 